{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eed9d5b",
   "metadata": {},
   "source": [
    "How to use:\n",
    "- In \"JiuTian-LION\\ram\" add \"pretrained/ram_swin_large_14m.pth\"\n",
    "- Run \"process_dataset_ram.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DirectML device found. Using AMD GPU.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch_directml\n",
    "    DEVICE = torch_directml.device()\n",
    "    print(\"found AMD GPU\")\n",
    "except (ImportError, RuntimeError):\n",
    "    DEVICE = 'cpu'\n",
    "    print(\"using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nassim\\anaconda3\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "c:\\Users\\Nassim\\anaconda3\\Lib\\site-packages\\timm\\models\\hub.py:4: FutureWarning: Importing from timm.models.hub is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "c:\\Users\\Nassim\\anaconda3\\Lib\\site-packages\\timm\\models\\registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "c:\\Users\\Nassim\\anaconda3\\Lib\\site-packages\\timm\\models\\helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully set device to DirectML: privateuseone:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertLMHeadModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/encoder/layer/0/crossattention/self/query is tied\n",
      "/encoder/layer/0/crossattention/self/key is tied\n",
      "/encoder/layer/0/crossattention/self/value is tied\n",
      "/encoder/layer/0/crossattention/output/dense is tied\n",
      "/encoder/layer/0/crossattention/output/LayerNorm is tied\n",
      "/encoder/layer/0/intermediate/dense is tied\n",
      "/encoder/layer/0/output/dense is tied\n",
      "/encoder/layer/0/output/LayerNorm is tied\n",
      "/encoder/layer/1/crossattention/self/query is tied\n",
      "/encoder/layer/1/crossattention/self/key is tied\n",
      "/encoder/layer/1/crossattention/self/value is tied\n",
      "/encoder/layer/1/crossattention/output/dense is tied\n",
      "/encoder/layer/1/crossattention/output/LayerNorm is tied\n",
      "/encoder/layer/1/intermediate/dense is tied\n",
      "/encoder/layer/1/output/dense is tied\n",
      "/encoder/layer/1/output/LayerNorm is tied\n",
      "--------------\n",
      "pretrained/ram_swin_large_14m.pth\n",
      "--------------\n",
      "load checkpoint from pretrained/ram_swin_large_14m.pth\n",
      "vit: swin_l\n",
      "RAM model loaded successfully on privateuseone:0.\n",
      "Loading dataset from coco_image_captions.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43287/43287 [4:32:01<00:00,  2.65it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving updated dataset to coco_image_captions_with_tags.csv...\n",
      "Processing complete!\n",
      "Total runtime: 16322.83 seconds\n",
      "Time per image: 0.38 seconds\n",
      "       image_id                                          image_url  \\\n",
      "75000    101017  http://images.cocodataset.org/train2017/000000...   \n",
      "75001    516084  http://images.cocodataset.org/train2017/000000...   \n",
      "75002     40596  http://images.cocodataset.org/train2017/000000...   \n",
      "75003     68502  http://images.cocodataset.org/train2017/000000...   \n",
      "75004    523262  http://images.cocodataset.org/train2017/000000...   \n",
      "\n",
      "                                               caption_1  \\\n",
      "75000  Two adults participating in frisbee football w...   \n",
      "75001  A man with a lasso riding a horse on water dur...   \n",
      "75002        A polar bear scratching its back on a tree.   \n",
      "75003  Herd of zebras and giraffes on the edge of a f...   \n",
      "75004            Group posing for a photo on a ski hill.   \n",
      "\n",
      "                                               caption_2  \\\n",
      "75000  A woman playing a game of Frisbee as a crowd o...   \n",
      "75001   Cowboy practicing his lasso skills on the beach.   \n",
      "75002  A bear reaching up towards a tree on a rocky h...   \n",
      "75003  A group of zebras in a grassy field with giraf...   \n",
      "75004  A large group of people standing outside by a ...   \n",
      "\n",
      "                                               caption_3  \\\n",
      "75000   Two girls playing a game of Freesbe at the park.   \n",
      "75001   A cowboy riding a horse is playing with a lasso.   \n",
      "75002         A polar bear is standing on its hind legs.   \n",
      "75003  Several zebras with giraffe in the background ...   \n",
      "75004  A crowd of people stand together to take a gro...   \n",
      "\n",
      "                                               caption_4  \\\n",
      "75000       Two women reaching for a Frisbee in the air.   \n",
      "75001     A man on a horse with a lasso during a sunset.   \n",
      "75002        A polar bear holding its head up in the sky   \n",
      "75003  The back end of several zebras can be seen in ...   \n",
      "75004  A group of skiers and snowboarders pose for a ...   \n",
      "\n",
      "                                               caption_5  \\\n",
      "75000  Two women ultimate frisbee players in action a...   \n",
      "75001  A man with a lasso riding on a horse on the be...   \n",
      "75002               A bear sits under a tree looking up.   \n",
      "75003  Zebras with their backs towards the camera are...   \n",
      "75004  A large group of people standing together in t...   \n",
      "\n",
      "                                                    tags  \\\n",
      "75000  frisbee | person | play | field | woman | man ...   \n",
      "75001  horse | man | ride | beach | sunset | cowboy h...   \n",
      "75002  bear | tree | stone | pine | sit | stand | zoo...   \n",
      "75003  zebra | field | giraffe | grass | group | herd...   \n",
      "75004  group | person | stand | snow | pose | ski | p...   \n",
      "\n",
      "                                       confidence_scores  \n",
      "75000  [0.9998212456703186, 0.9996734857559204, 0.999...  \n",
      "75001  [0.99998939037323, 0.9992256164550781, 0.99914...  \n",
      "75002  [0.9999257326126099, 0.9997163414955139, 0.984...  \n",
      "75003  [0.9999896287918091, 0.9994431138038635, 0.999...  \n",
      "75004  [0.9999938011169434, 0.9999572038650513, 0.997...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from models.ram import ram\n",
    "from transform import get_transform\n",
    "\n",
    "# --- Configuration ---\n",
    "DATASET_PATH = 'coco_image_captions.csv'\n",
    "# Path where the new dataset will be saved\n",
    "OUTPUT_PATH = 'coco_image_captions_with_tags.csv'\n",
    "# Path to the pretrained model weights\n",
    "PRETRAINED_MODEL_PATH = 'pretrained/ram_swin_large_14m.pth'\n",
    "# Set the image size required by the model\n",
    "IMAGE_SIZE = 384\n",
    "try:\n",
    "    import torch_directml\n",
    "    DEVICE = torch_directml.device()\n",
    "    print(f\"Successfully set device to DirectML: {DEVICE}\")\n",
    "except (ImportError, RuntimeError) as e:\n",
    "    print(f\"Could not initialize DirectML, falling back to CPU. Error: {e}\")\n",
    "    DEVICE = 'cpu'\n",
    "\n",
    "# --- Model Loading ---\n",
    "def load_ram_model(model_path, image_size):\n",
    "    \"\"\"Loads the Recognize Anything Model (RAM).\"\"\"\n",
    "    os.environ['CONFIG_PATH'] = './models'\n",
    "    \n",
    "    model = ram(\n",
    "        pretrained=model_path,\n",
    "        image_size=image_size,\n",
    "        vit='swin_l'\n",
    "    )\n",
    "    model.eval()\n",
    "    model = model.to(DEVICE)\n",
    "    print(f\"RAM model loaded successfully on {DEVICE}.\")\n",
    "    return model\n",
    "\n",
    "CUSTOM_THRESHOLD = 0.5\n",
    "MAX_TAGS = 40\n",
    "\n",
    "def generate_tags_with_scores(model, image, transform, max_tags, threshold):\n",
    "    \"\"\"\n",
    "    Generates a rich but concise set of tags and scores using a \n",
    "    Top-K (max_tags) and minimum confidence floor (threshold) approach.\n",
    "    \"\"\"\n",
    "    image_tensor = transform(image).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Model Forward Pass to get confidence scores for all tags \n",
    "        image_embeds = model.image_proj(model.visual_encoder(image_tensor))\n",
    "        image_atts = torch.ones(image_embeds.size()[:-1], dtype=torch.long).to(DEVICE)\n",
    "        bs = image_embeds.shape[0]\n",
    "        projected_label_embed = torch.nn.functional.relu(model.wordvec_proj(model.label_embed))\n",
    "        label_embed = projected_label_embed.unsqueeze(0).repeat(bs, 1, 1)\n",
    "        tagging_embed = model.tagging_head(\n",
    "            encoder_embeds=label_embed,\n",
    "            encoder_hidden_states=image_embeds,\n",
    "            encoder_attention_mask=image_atts,\n",
    "            return_dict=False,\n",
    "            mode='tagging',\n",
    "        )\n",
    "        logits = model.fc(tagging_embed[0]).squeeze(-1)\n",
    "        confidences = torch.sigmoid(logits).squeeze()\n",
    "        \n",
    "        # Sort scores and get the top K candidates to set a hard limit\n",
    "        sorted_scores, sorted_indices = torch.sort(confidences, descending=True)\n",
    "        top_k_scores = sorted_scores[:max_tags]\n",
    "        top_k_indices = sorted_indices[:max_tags]\n",
    "\n",
    "        # From these top K, filter out any that are below the confidence threshold\n",
    "        final_indices = top_k_indices[top_k_scores > threshold]\n",
    "        final_scores = top_k_scores[top_k_scores > threshold]\n",
    "        \n",
    "        # Convert to CPU and numpy for tag lookup\n",
    "        final_indices = final_indices.cpu().numpy()\n",
    "        final_scores = final_scores.cpu().numpy().tolist()\n",
    "\n",
    "        # Exclude deleted tags from the final list\n",
    "        valid_indices = [i for i in final_indices if i not in model.delete_tag_index]\n",
    "        if not valid_indices:\n",
    "             return \"\", []\n",
    "\n",
    "        # Create a map of index-to-score to correctly get scores for valid tags\n",
    "        score_map = {idx: score for idx, score in zip(final_indices, final_scores)}\n",
    "        valid_scores = [score_map[i] for i in valid_indices]\n",
    "\n",
    "        # Get the final tags\n",
    "        predicted_tags = model.tag_list[valid_indices]\n",
    "        \n",
    "        tag_string = ' | '.join(predicted_tags)\n",
    "        \n",
    "        return tag_string, valid_scores\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    \"\"\"Downloads an image from a URL and returns it as a PIL Image.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        return image\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_dataset(df, model, transform):\n",
    "    \"\"\"\n",
    "    Processes the DataFrame to add tags and confidence scores.\n",
    "    \"\"\"\n",
    "    new_tags = []\n",
    "    new_scores = []\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing images\"):\n",
    "        image_url = row['image_url']\n",
    "        image = download_image(image_url)\n",
    "        \n",
    "        if image:\n",
    "            # Pass both MAX_TAGS and CUSTOM_THRESHOLD to the function\n",
    "            tags, scores = generate_tags_with_scores(model, image, transform, MAX_TAGS, CUSTOM_THRESHOLD)\n",
    "            new_tags.append(tags)\n",
    "            new_scores.append(scores)\n",
    "        else:\n",
    "            # Append empty values if image download fails\n",
    "            new_tags.append(\"\")\n",
    "            new_scores.append([])\n",
    "            \n",
    "    df['tags'] = new_tags\n",
    "    df['confidence_scores'] = new_scores\n",
    "    return df\n",
    "\n",
    "\n",
    "import time\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the model and image transformer\n",
    "    ram_model = load_ram_model(PRETRAINED_MODEL_PATH, IMAGE_SIZE)\n",
    "    image_transform = get_transform(image_size=IMAGE_SIZE)\n",
    "\n",
    "    # Load the dataset\n",
    "    print(f\"Loading dataset from {DATASET_PATH}...\")\n",
    "    coco_df = pd.read_csv(DATASET_PATH)\n",
    "    \n",
    "    # --- TESTING ---\n",
    "    num_imgs_start = 75000\n",
    "    num_imgs_end = 118287+1\n",
    "    coco_df = coco_df[num_imgs_start:]\n",
    "    # print(f\"Testing with the first {num_imgs} images...\")\n",
    "    # ---------------------------------\n",
    "    start_time = time.time()\n",
    "    # Process the dataset to get tags and scores\n",
    "    processed_df = process_dataset(coco_df, ram_model, image_transform)\n",
    "\n",
    "    # 4. Save the new dataset\n",
    "    print(f\"Saving updated dataset to {OUTPUT_PATH}...\")\n",
    "    processed_df.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(\"Processing complete!\")\n",
    "    print(f\"Total runtime: {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"Time per image: {(time.time() - start_time)/(num_imgs_end-num_imgs_start):.2f} seconds\")\n",
    "\n",
    "    print(processed_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "935112e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 7 hours is 72000.0\n",
      "Remaining data to process: 46287.0\n",
      "Time to process remaining data: 4.24 hours\n"
     ]
    }
   ],
   "source": [
    "hours = 7\n",
    "data_count = hours * 60 * 60 / 0.35  \n",
    "print(f\"Data for {hours} hours is {round(data_count,0)}\")\n",
    "total_data = 118287\n",
    "print(f\"Remaining data to process: {round(total_data - data_count,0)}\")\n",
    "print(f\"Time to process remaining data: {round((total_data - data_count) * 0.33 / 60 / 60,2)} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267ec146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run for 43288 images is 4.21 hours\n"
     ]
    }
   ],
   "source": [
    "num_imgs_start = 75000\n",
    "num_imgs_end = 118287+1\n",
    "time_per_image = 0.35\n",
    "print(f\"Time to run for {num_imgs_end-num_imgs_start} images is {round((num_imgs_end-num_imgs_start)*time_per_image/60/60,2)} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c20f0",
   "metadata": {},
   "source": [
    "**In case of error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01128830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = 'coco_image_captions.csv'\n",
    "OUTPUT_PATH = 'coco_image_captions_with_tags.csv'\n",
    "\n",
    "# Load the processed dataset (the one with missing tags)\n",
    "processed_df = pd.read_csv(OUTPUT_PATH)\n",
    "\n",
    "# Identify rows where tags are missing or empty\n",
    "missing_df = processed_df[processed_df['tags'].isna() | (processed_df['tags'].str.strip() == '')]\n",
    "\n",
    "print(f\"Found {len(missing_df)} images with missing tags.\")\n",
    "missing_df.head()\n",
    "\n",
    "def extract_image_id(url):\n",
    "    match = re.search(r'/(\\d+)\\.jpg$', url)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "missing_df['image_id'] = missing_df['image_url'].apply(extract_image_id)\n",
    "missing_df[['image_url', 'image_id']].head()\n",
    "\n",
    "from models.ram import ram\n",
    "from transform import get_transform\n",
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Config ---\n",
    "PRETRAINED_MODEL_PATH = 'pretrained/ram_swin_large_14m.pth'\n",
    "IMAGE_SIZE = 384\n",
    "CUSTOM_THRESHOLD = 0.5\n",
    "MAX_TAGS = 40\n",
    "\n",
    "# --- Device setup ---\n",
    "try:\n",
    "    import torch_directml\n",
    "    DEVICE = torch_directml.device()\n",
    "except:\n",
    "    DEVICE = 'cpu'\n",
    "\n",
    "# --- Load RAM ---\n",
    "def load_ram_model(model_path, image_size):\n",
    "    import os\n",
    "    os.environ['CONFIG_PATH'] = './models'\n",
    "    model = ram(pretrained=model_path, image_size=image_size, vit='swin_l')\n",
    "    model.eval().to(DEVICE)\n",
    "    return model\n",
    "\n",
    "ram_model = load_ram_model(PRETRAINED_MODEL_PATH, IMAGE_SIZE)\n",
    "transform = get_transform(image_size=IMAGE_SIZE)\n",
    "\n",
    "import time\n",
    "\n",
    "def download_image_with_retry(url, retries=3, delay=2):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            return Image.open(BytesIO(response.content))\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Attempt {attempt+1} failed for {url}: {e}\")\n",
    "            time.sleep(delay)\n",
    "    return None\n",
    "\n",
    "new_tags = []\n",
    "new_scores = []\n",
    "\n",
    "for i, row in tqdm(missing_df.iterrows(), total=len(missing_df), desc=\"Reprocessing missing images\"):\n",
    "    image = download_image_with_retry(row['image_url'])\n",
    "    if image:\n",
    "        tags, scores = generate_tags_with_scores(ram_model, image, transform, MAX_TAGS, CUSTOM_THRESHOLD)\n",
    "        new_tags.append(tags)\n",
    "        new_scores.append(scores)\n",
    "    else:\n",
    "        new_tags.append(\"\")\n",
    "        new_scores.append([])\n",
    "\n",
    "missing_df['tags'] = new_tags\n",
    "missing_df['confidence_scores'] = new_scores\n",
    "\n",
    "# Merge the fixed rows back into the main dataframe\n",
    "updated_df = processed_df.copy()\n",
    "updated_df.set_index('image_url', inplace=True)\n",
    "missing_df.set_index('image_url', inplace=True)\n",
    "\n",
    "# Update only those rows that were missing\n",
    "updated_df.update(missing_df[['tags', 'confidence_scores']])\n",
    "\n",
    "# Save final corrected dataset\n",
    "updated_df.reset_index(inplace=True)\n",
    "updated_df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(\"Dataset successfully updated with missing image tags.\")\n",
    "\n",
    "still_missing = updated_df[updated_df['tags'].isna() | (updated_df['tags'].str.strip() == '')]\n",
    "print(f\"Remaining missing tags: {len(still_missing)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
